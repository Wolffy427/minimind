{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c2f6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aligames/anaconda3/envs/lm_eval/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('./model/hf/minimind_full_sft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd31b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lm_eval\n",
    "from lm_eval.utils import setup_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0740f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model_minimind import MiniMindForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef65a554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniMindForCausalLM(\n",
       "  (model): MiniMindModel(\n",
       "    (embed_tokens): Embedding(6400, 512)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x MiniMindBlock(\n",
       "        (self_attn): Attention(\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (k_proj): Linear(in_features=512, out_features=128, bias=False)\n",
       "          (v_proj): Linear(in_features=512, out_features=128, bias=False)\n",
       "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (input_layernorm): RMSNorm()\n",
       "        (post_attention_layernorm): RMSNorm()\n",
       "        (mlp): FeedForward(\n",
       "          (gate_proj): Linear(in_features=512, out_features=1408, bias=False)\n",
       "          (down_proj): Linear(in_features=1408, out_features=512, bias=False)\n",
       "          (up_proj): Linear(in_features=512, out_features=1408, bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=6400, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_logging('DEBUG')\n",
    "model = MiniMindForCausalLM.from_pretrained('./model/hf/minimind_full_sft', torch_dtype='auto')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb2ee363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24:16:04:50 WARNING  [models.huggingface:107] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2025-07-24:16:04:50 WARNING  [models.huggingface:525] HF model type is neither marked as CausalLM or Seq2SeqLM.                     This is expected if your model requires `trust_remote_code=True` but may be an error otherwise.Setting backend to causal\n",
      "2025-07-24:16:04:50 INFO     [models.huggingface:533] Model type cannot be determined. Using default model type 'causal'\n",
      "2025-07-24:16:04:50 WARNING  [models.huggingface:316] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n"
     ]
    }
   ],
   "source": [
    "model = lm_eval.models.huggingface.HFLM(pretrained=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce87c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HF_ENDPOINT=https://hf-mirror.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "080a1d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24:16:05:03 INFO     [evaluator:198] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "2025-07-24:16:05:03 INFO     [evaluator:252] Using pre-initialized model\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "Couldn't reach 'ceval/ceval-exam' on the Hub (LocalEntryNotFoundError)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = \u001b[43mlm_eval\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimple_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mceval-valid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_fewshot\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/lm-evaluation-harness/lm_eval/utils.py:439\u001b[39m, in \u001b[36mpositional_deprecated.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) != \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inspect.ismethod(fn) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m:\n\u001b[32m    434\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    435\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWARNING: using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with positional arguments is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    436\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdeprecated and will be disallowed in a future version of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    437\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlm-evaluation-harness!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    438\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/lm-evaluation-harness/lm_eval/evaluator.py:277\u001b[39m, in \u001b[36msimple_evaluate\u001b[39m\u001b[34m(model, model_args, tasks, num_fewshot, batch_size, max_batch_size, device, use_cache, cache_requests, rewrite_requests_cache, delete_requests_cache, limit, samples, bootstrap_iters, check_integrity, write_out, log_samples, evaluation_tracker, system_instruction, apply_chat_template, fewshot_as_multiturn, gen_kwargs, task_manager, verbosity, predict_only, random_seed, numpy_random_seed, torch_random_seed, fewshot_random_seed, confirm_run_unsafe_code, metadata)\u001b[39m\n\u001b[32m    268\u001b[39m     metadata = (\n\u001b[32m    269\u001b[39m         simple_parse_args_string(model_args)\n\u001b[32m    270\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_args, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    273\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    274\u001b[39m     ) | (metadata \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[32m    275\u001b[39m     task_manager = TaskManager(metadata=metadata)\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m task_dict = \u001b[43mget_task_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[38;5;66;03m# helper function to recursively apply config overrides to leaf subtasks, skipping their constituent groups.\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[38;5;66;03m# (setting of num_fewshot ; bypassing metric calculation ; setting fewshot seed)\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_adjust_config\u001b[39m(task_dict):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/lm-evaluation-harness/lm_eval/tasks/__init__.py:635\u001b[39m, in \u001b[36mget_task_dict\u001b[39m\u001b[34m(task_name_list, task_manager)\u001b[39m\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m task_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    633\u001b[39m         task_manager = TaskManager()\n\u001b[32m--> \u001b[39m\u001b[32m635\u001b[39m     task_name_from_string_dict = \u001b[43mtask_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_task_or_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstring_task_name_list\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task_element \u001b[38;5;129;01min\u001b[39;00m others_task_name_list:\n\u001b[32m    640\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(task_element, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/lm-evaluation-harness/lm_eval/tasks/__init__.py:426\u001b[39m, in \u001b[36mTaskManager.load_task_or_group\u001b[39m\u001b[34m(self, task_list)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(task_list, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    423\u001b[39m     task_list = [task_list]\n\u001b[32m    425\u001b[39m all_loaded_tasks = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[43mcollections\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChainMap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_individual_task_or_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtask_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m )\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m all_loaded_tasks\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/lm-evaluation-harness/lm_eval/tasks/__init__.py:428\u001b[39m, in \u001b[36mTaskManager.load_task_or_group.<locals>.<lambda>\u001b[39m\u001b[34m(task)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(task_list, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    423\u001b[39m     task_list = [task_list]\n\u001b[32m    425\u001b[39m all_loaded_tasks = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    426\u001b[39m     collections.ChainMap(\n\u001b[32m    427\u001b[39m         *\u001b[38;5;28mmap\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m task: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_individual_task_or_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    429\u001b[39m             task_list,\n\u001b[32m    430\u001b[39m         )\n\u001b[32m    431\u001b[39m     )\n\u001b[32m    432\u001b[39m )\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m all_loaded_tasks\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/lm-evaluation-harness/lm_eval/tasks/__init__.py:410\u001b[39m, in \u001b[36mTaskManager._load_individual_task_or_group\u001b[39m\u001b[34m(self, name_or_config, parent_name, update_config)\u001b[39m\n\u001b[32m    400\u001b[39m         group_name, subtask_list = _get_group_and_subtask_from_config(\n\u001b[32m    401\u001b[39m             group_config\n\u001b[32m    402\u001b[39m         )\n\u001b[32m    404\u001b[39m fn = partial(\n\u001b[32m    405\u001b[39m     \u001b[38;5;28mself\u001b[39m._load_individual_task_or_group,\n\u001b[32m    406\u001b[39m     parent_name=group_name,\n\u001b[32m    407\u001b[39m     update_config=update_config,\n\u001b[32m    408\u001b[39m )\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     group_name: \u001b[38;5;28mdict\u001b[39m(\u001b[43mcollections\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChainMap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mreversed\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubtask_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    411\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/lm-evaluation-harness/lm_eval/tasks/__init__.py:326\u001b[39m, in \u001b[36mTaskManager._load_individual_task_or_group\u001b[39m\u001b[34m(self, name_or_config, parent_name, update_config)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._name_is_task(name_or_config) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._name_is_python_task(\n\u001b[32m    323\u001b[39m     name_or_config\n\u001b[32m    324\u001b[39m ):\n\u001b[32m    325\u001b[39m     task_config = \u001b[38;5;28mself\u001b[39m._get_config(name_or_config)\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname_or_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    328\u001b[39m     subtask_list = \u001b[38;5;28mself\u001b[39m._get_tasklist(name_or_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/lm-evaluation-harness/lm_eval/tasks/__init__.py:286\u001b[39m, in \u001b[36mTaskManager._load_individual_task_or_group.<locals>._load_task\u001b[39m\u001b[34m(config, task)\u001b[39m\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    285\u001b[39m         config[\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m] = config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     task_object = \u001b[43mConfigurableTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {task: task_object}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/lm-evaluation-harness/lm_eval/api/task.py:865\u001b[39m, in \u001b[36mConfigurableTask.__init__\u001b[39m\u001b[34m(self, data_dir, cache_dir, download_mode, config)\u001b[39m\n\u001b[32m    858\u001b[39m             eval_logger.warning(\n\u001b[32m    859\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Task: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.config.task\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] metric \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is defined, but higher_is_better is not. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    860\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33musing default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    861\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhigher_is_better=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mis_higher_better(metric_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    862\u001b[39m             )\n\u001b[32m    863\u001b[39m             \u001b[38;5;28mself\u001b[39m._higher_is_better[metric_name] = is_higher_better(metric_name)\n\u001b[32m--> \u001b[39m\u001b[32m865\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[38;5;28mself\u001b[39m._training_docs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    867\u001b[39m \u001b[38;5;28mself\u001b[39m._fewshot_docs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/lm-evaluation-harness/lm_eval/api/task.py:993\u001b[39m, in \u001b[36mConfigurableTask.download\u001b[39m\u001b[34m(self, dataset_kwargs, **kwargs)\u001b[39m\n\u001b[32m    989\u001b[39m     \u001b[38;5;28mself\u001b[39m.dataset = \u001b[38;5;28mself\u001b[39m.config.custom_dataset(\n\u001b[32m    990\u001b[39m         **(\u001b[38;5;28mself\u001b[39m.config.metadata \u001b[38;5;129;01mor\u001b[39;00m {}), **(\u001b[38;5;28mself\u001b[39m.config.dataset_kwargs \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[32m    991\u001b[39m     )\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m993\u001b[39m     \u001b[38;5;28mself\u001b[39m.dataset = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mDATASET_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mDATASET_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lm_eval/lib/python3.12/site-packages/datasets/load.py:1392\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[39m\n\u001b[32m   1387\u001b[39m verification_mode = VerificationMode(\n\u001b[32m   1388\u001b[39m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode.BASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode.ALL_CHECKS\n\u001b[32m   1389\u001b[39m )\n\u001b[32m   1391\u001b[39m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1392\u001b[39m builder_instance = \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[32m   1408\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lm_eval/lib/python3.12/site-packages/datasets/load.py:1132\u001b[39m, in \u001b[36mload_dataset_builder\u001b[39m\u001b[34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, **config_kwargs)\u001b[39m\n\u001b[32m   1130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1131\u001b[39m     features = _fix_for_backward_compatible_features(features)\n\u001b[32m-> \u001b[39m\u001b[32m1132\u001b[39m dataset_module = \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[38;5;66;03m# Get dataset builder class\u001b[39;00m\n\u001b[32m   1142\u001b[39m builder_kwargs = dataset_module.builder_kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lm_eval/lib/python3.12/site-packages/datasets/load.py:1031\u001b[39m, in \u001b[36mdataset_module_factory\u001b[39m\u001b[34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[39m\n\u001b[32m   1026\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[32m   1027\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m   1028\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find any data file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1029\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m on the Hugging Face Hub either: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e1).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1030\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1033\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find any data file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/lm_eval/lib/python3.12/site-packages/datasets/load.py:953\u001b[39m, in \u001b[36mdataset_module_factory\u001b[39m\u001b[34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m LocalEntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    945\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    946\u001b[39m         e.__cause__,\n\u001b[32m    947\u001b[39m         (\n\u001b[32m   (...)\u001b[39m\u001b[32m    951\u001b[39m         ),\n\u001b[32m    952\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt reach \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m on the Hub (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    954\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    955\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectionError\u001b[39m: Couldn't reach 'ceval/ceval-exam' on the Hub (LocalEntryNotFoundError)"
     ]
    }
   ],
   "source": [
    "result = lm_eval.simple_evaluate(\n",
    "    model=model,\n",
    "    tasks=['ceval-valid'],\n",
    "    num_fewshot=0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
