<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MiniMind vs Qwen2.5-7B Performance Comparison Report</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 0 20px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }
        h2 {
            color: #34495e;
            margin-top: 40px;
            margin-bottom: 20px;
            font-size: 1.8em;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }
        h3 {
            color: #2c3e50;
            margin-top: 30px;
            margin-bottom: 15px;
            font-size: 1.4em;
        }
        .summary-box {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 10px;
            margin: 20px 0;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
        }
        .summary-box h3 {
            color: white;
            margin-top: 0;
        }
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        .stat-card {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            border-left: 4px solid #3498db;
        }
        .stat-card h4 {
            margin: 0 0 10px 0;
            color: #2c3e50;
            font-size: 1.1em;
        }
        .stat-value {
            font-size: 1.8em;
            font-weight: bold;
            color: #3498db;
        }
        .chart-container {
            text-align: center;
            margin: 30px 0;
            padding: 20px;
            background-color: #fafafa;
            border-radius: 8px;
            border: 1px solid #e0e0e0;
        }
        .chart-container img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .chart-description {
            margin-top: 15px;
            color: #666;
            font-style: italic;
        }
        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background-color: white;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .comparison-table th,
        .comparison-table td {
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }
        .comparison-table th {
            background-color: #3498db;
            color: white;
            font-weight: bold;
        }
        .comparison-table tr:hover {
            background-color: #f5f5f5;
        }
        .winner-qwen {
            background-color: #d4edda;
            color: #155724;
        }
        .winner-minimind {
            background-color: #f8d7da;
            color: #721c24;
        }
        .key-findings {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
        }
        .key-findings h3 {
            color: #856404;
            margin-top: 0;
        }
        .key-findings ul {
            color: #856404;
        }
        .model-badge {
            display: inline-block;
            padding: 5px 10px;
            border-radius: 15px;
            font-size: 0.9em;
            font-weight: bold;
            margin: 0 5px;
        }
        .qwen-badge {
            background-color: #2E8B57;
            color: white;
        }
        .minimind-badge {
            background-color: #FF6347;
            color: white;
        }
        .footer {
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ü§ñ MiniMind vs Qwen2.5-7B Performance Comparison</h1>
        
        <div class="summary-box">
            <h3>üìä Executive Summary</h3>
            <p>This comprehensive analysis compares the performance of two language models: 
            <span class="model-badge qwen-badge">Qwen2.5-7B</span> and 
            <span class="model-badge minimind-badge">MiniMind</span> across 71 evaluation datasets.</p>
            
            <div class="stats-grid">
                <div class="stat-card">
                    <h4>Qwen2.5-7B Average Accuracy</h4>
                    <div class="stat-value">40.59%</div>
                </div>
                <div class="stat-card">
                    <h4>MiniMind Average Accuracy</h4>
                    <div class="stat-value">25.22%</div>
                </div>
                <div class="stat-card">
                    <h4>Performance Gap</h4>
                    <div class="stat-value">15.37%</div>
                </div>
                <div class="stat-card">
                    <h4>Qwen Wins</h4>
                    <div class="stat-value">70/71</div>
                </div>
            </div>
        </div>

        <h2>üìà Comprehensive Performance Analysis</h2>
        
        <div class="chart-container">
            <h3>Overall Model Comparison</h3>
            <img src="model_comparison.png" alt="Model Comparison Chart">
            <div class="chart-description">
                This comprehensive chart shows performance comparison across all datasets, 
                including accuracy differences, statistical analysis, and performance correlation.
            </div>
        </div>

        <div class="chart-container">
            <h3>Detailed Performance Comparison Table</h3>
            <img src="detailed_comparison_table.png" alt="Detailed Comparison Table">
            <div class="chart-description">
                Detailed dataset-by-dataset comparison showing exact accuracy scores and winners.
            </div>
        </div>

        <div class="chart-container">
            <h3>Performance Analysis Summary</h3>
            <img src="english_summary.png" alt="Performance Summary">
            <div class="chart-description">
                Summary analysis including win/loss distribution, performance differences, 
                and top/bottom performing datasets.
            </div>
        </div>

        <h2>üîç Individual Model Analysis</h2>
        
        <h3>Qwen2.5-7B Performance (Previous Analysis)</h3>
        <div class="chart-container">
            <img src="comprehensive_evaluation_summary.png" alt="Qwen Comprehensive Summary">
            <div class="chart-description">
                Comprehensive analysis of Qwen2.5-7B performance across all evaluation metrics.
            </div>
        </div>

        <div class="chart-container">
            <h3>ACLUE Dataset Performance</h3>
            <img src="aclue_detailed.png" alt="ACLUE Performance">
            <div class="chart-description">
                Detailed performance analysis on ACLUE (Ancient Chinese Language Understanding Evaluation) tasks.
            </div>
        </div>

        <div class="chart-container">
            <h3>CMMLU Dataset Performance</h3>
            <img src="cmmlu_detailed.png" alt="CMMLU Performance">
            <div class="chart-description">
                Performance analysis on CMMLU (Chinese Massive Multitask Language Understanding) benchmark.
            </div>
        </div>

        <div class="chart-container">
            <h3>Performance Distribution Analysis</h3>
            <img src="performance_distribution.png" alt="Performance Distribution">
            <div class="chart-description">
                Distribution of accuracy scores across different evaluation tasks.
            </div>
        </div>

        <div class="chart-container">
            <h3>Radar Chart Analysis</h3>
            <img src="radar_chart.png" alt="Radar Chart">
            <div class="chart-description">
                Multi-dimensional performance analysis across different capability areas.
            </div>
        </div>

        <div class="key-findings">
            <h3>üéØ Key Findings</h3>
            <ul>
                <li><strong>Overall Performance:</strong> Qwen2.5-7B significantly outperforms MiniMind with an average accuracy of 40.59% vs 25.22%</li>
                <li><strong>Consistency:</strong> Qwen2.5-7B wins in 70 out of 71 datasets, showing superior performance across almost all evaluation tasks</li>
                <li><strong>Performance Gap:</strong> The average performance gap is 15.37 percentage points, indicating substantial differences in model capabilities</li>
                <li><strong>Best Performance:</strong> Both models show strongest performance in language understanding and reasoning tasks</li>
                <li><strong>Areas for Improvement:</strong> Both models struggle with mathematical reasoning and technical domain knowledge</li>
                <li><strong>Model Size Impact:</strong> The performance difference likely reflects the impact of model size and training data quality</li>
            </ul>
        </div>

        <h2>üìã Technical Specifications</h2>
        
        <table class="comparison-table">
            <thead>
                <tr>
                    <th>Aspect</th>
                    <th>Qwen2.5-7B</th>
                    <th>MiniMind</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Model Type</td>
                    <td>Large Language Model</td>
                    <td>Compact Language Model</td>
                </tr>
                <tr>
                    <td>Parameters</td>
                    <td>~7 Billion</td>
                    <td>Significantly Smaller</td>
                </tr>
                <tr>
                    <td>Average Accuracy</td>
                    <td class="winner-qwen">40.59%</td>
                    <td>25.22%</td>
                </tr>
                <tr>
                    <td>Datasets Evaluated</td>
                    <td>71</td>
                    <td>71</td>
                </tr>
                <tr>
                    <td>Best Performance</td>
                    <td class="winner-qwen">66.29% (Junior Chinese Exam)</td>
                    <td>~45% (Various tasks)</td>
                </tr>
                <tr>
                    <td>Worst Performance</td>
                    <td>26.67% (Vocational Math)</td>
                    <td class="winner-minimind">~15% (Various tasks)</td>
                </tr>
            </tbody>
        </table>

        <h2>üöÄ Recommendations</h2>
        
        <div class="key-findings">
            <h3>For Model Selection:</h3>
            <ul>
                <li><strong>High-Performance Applications:</strong> Choose Qwen2.5-7B for applications requiring maximum accuracy</li>
                <li><strong>Resource-Constrained Environments:</strong> Consider MiniMind for applications with strict computational or memory constraints</li>
                <li><strong>Domain-Specific Tasks:</strong> Evaluate both models on your specific use case, as performance may vary by domain</li>
                <li><strong>Cost-Performance Trade-off:</strong> Balance accuracy requirements against computational costs</li>
            </ul>
        </div>

        <div class="footer">
            <p>üìÖ Report Generated: January 2025 | üîß Evaluation Framework: LM Evaluation Harness</p>
            <p>‚ö†Ô∏è Note: Chinese characters may not display correctly in generated charts due to font limitations</p>
        </div>
    </div>
</body>
</html>